# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# Google Gemini API (Required - for AI story generation)
# Get your API key from: https://makersuite.google.com/app/apikey
# Free tier available with generous limits
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp

# Deployment Configuration (for production/Render)
# Frontend URL for CORS (set automatically by Render, or manually for other platforms)
# Example: voiceclone-frontend.onrender.com (without https://)
FRONTEND_URL=
ENVIRONMENT=development  # Options: development, production

# RunPod Serverless (Required - for fast GPU synthesis)
# Sign up at: https://www.runpod.io/console/serverless
# Get your API key from: https://www.runpod.io/console/serverless/user/settings
# Create endpoint following instructions in README.md
RUNPOD_API_KEY=your_runpod_api_key_here
RUNPOD_ENDPOINT_ID=your_runpod_endpoint_id_here

# Use RunPod by default (true = fast cloud GPU, false = slow local GPU)
# Recommended: true (100x faster, ~$0.50 per story)
# Local GPU: false (very slow, 6-7 hours per story on RTX 3050)
USE_RUNPOD=true

# =============================================================================
# TTS GENERATION SETTINGS
# =============================================================================

TTS_SAMPLE_RATE=24000
TTS_EMOTION_PRESET=neutral  # Options: neutral, happy, sad, angry, surprised
TTS_SPEED=1.0  # Range: 0.5 to 2.0

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================

OUTPUT_DIR=./output
OUTPUT_FORMAT=wav  # Options: wav, mp3, flac
AUDIO_BITRATE=192k  # For mp3/flac format

# =============================================================================
# LOGGING & PERFORMANCE
# =============================================================================

LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
DEVICE=cuda  # Options: cuda, cpu, mps (for Mac M1/M2) - used only if USE_RUNPOD=false
TORCH_THREADS=4  # Number of CPU threads for PyTorch (adjust based on your CPU)

# =============================================================================
# REQUEST LIMITS & TIMEOUTS
# =============================================================================

MAX_TEXT_LENGTH=5000  # Maximum characters for TTS input
MAX_AUDIO_SIZE_MB=50  # Maximum audio file size in MB for reference voices
REQUEST_TIMEOUT_SECONDS=600  # Maximum request processing time (10 minutes for model loading)
RUNPOD_TIMEOUT_SECONDS=300  # Timeout for RunPod API calls (5 minutes)

# =============================================================================
# OPTIONAL: ALTERNATIVE LLM PROVIDERS
# =============================================================================
# Uncomment and configure if you want to use OpenAI or Anthropic instead of Gemini

# OpenAI (GPT-4, GPT-3.5)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Claude
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-opus-20240229
